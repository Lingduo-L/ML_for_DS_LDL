# ML_for_DS_LDL


**Medical Data Binary Classification Jan 2022 - Feb 2022**

• Performed binary classification on the Vertebral dataset using k-nearest neighbors algorithm and achieved a low
testing error of 8% by finding optimal k value and exploring distance metrics and weighting.
• Conducted pre-processing and exploratory data analysis, and calculated performance metrics using sklearn.neighbors.DM.


**Power Plant Energy Output Prediction and Analysis February 2022**

• Built a multiple linear regression model with 9600 records to predict the hourly electrical energy output of the plant.
• Refined sklearn KNN regression model, achieved a 20% reduction in testing error by eliminating non-significant variables.


**Time Series Classification March 2022**

• Extracted time-domain features from time series data and established a 90% bootstrap confidence interval using Python.
• Implemented a logistic regression model using scikit-learn to accurately classify human activities.
• Employed recursive feature elimination with cross-validation to select the optimal number of features and achieved a
F1 score of 94%.


**Regression Model on Communities and Crime Dataset April 2022**

• Built and fit LASSO regression model with 5-fold cross-validated Lagrange multiplier, achieving a test MSE of 0.017.
• Constructed and trained L1 penalized Gradient Boosting Tree to the data with XGBoost, determined the regular-
ization term using cross-validation.


**Imbalanced APS Failure and Operational Data Classification May 2022**

• Improved classification of imbalanced data using SMOTE pre-processing
• Built and evaluated a random forest model on a 60,000-row dataset, compensated class imbalance, achieved 0.007 out
of bag error.
• Constructed a model tree using L1-penalized logistic regression and XGBoost, optimizing regularization term via
cross-validation, achieved 98% AUC, improving APS failure prediction.


**Multi-Class and Multi-Label Anuran Calls Data Set Classification/Clustering May 2022**

• Employed SMOTE to address class imbalance.
• Developed a multi-label SVM classifier with regularization using scikit-learn.
• Utilized k-means clustering with Silhouettes analysis to automatically select the optimal number of clusters.
• Evaluated the quality of clusters by computing average Hamming distance, score, and loss using Monte-Carlo simulation.


**Breast Cancer Diagnosis: Supervised, Semi-Supervised, and Unsupervised Learning May 2022**

• Achieved best performance with Monte-Carlo simulation across supervised, unsupervised, and semi-supervised learning
with an average accuracy score of 0.960 and AUC score of 0.967 on test set.


**Active vs. Passive Learning for Banknote Authentication May 2022**

• Implemented and compared passive/active learning methods for binary classification.
• Evaluated SVM performance using Monte Carlo simulations and learning curves on banknote authentication data.
• Achieved test errors below 0.21 for passive and active learning methods.


**Sentiment Analysis Classifier of Reviews June 2022**

• Used Keras for word embedding with an accuracy of 100% on review data.
• Trained MLP model for sentiment classification with 3 dense hidden layers of 50 ReLU units and a single sigmoid output
neuron, gained score at 75%.
• Built one-dimensional CNN model with the same parameters as the MLP model, gained test score at 67.8%.
• LSTM with 256-unit dense layer, 32-element word vectors, and 0.2 dropout rate, trained for 10-50 epochs with batch size
of 10, achieving 62% score.
